# ğŸ• Datapizza Streamlit LLM Interface

> Interfaccia Streamlit modulare per interagire con LLM locali (Ollama), remoti e cloud.
> Progetto Open Source della community **DeepAiUG**.

[![Version](https://img.shields.io/badge/version-1.6.1-blue.svg)](https://github.com/EnzoGitHub27/datapizza-streamlit-interface/releases/tag/v1.6.1)
[![Python](https://img.shields.io/badge/python-3.9+-green.svg)](https://python.org)
[![Streamlit](https://img.shields.io/badge/streamlit-1.28+-red.svg)](https://streamlit.io)
[![License](https://img.shields.io/badge/license-MIT-yellow.svg)](LICENSE)

---

## âœ¨ Features

- ğŸ¤– **Multi-provider**: Ollama (locale), Remote host, Cloud (OpenAI, Anthropic, Google)
- ğŸ§  **Approccio Socratico** - Bottoni per esplorare prospettive alternative! â­ NEW
- ğŸŒŠ **Streaming Responses** - Risposte token-by-token in tempo reale!
- ğŸ’¬ **Conversazioni multi-turno** con memoria del contesto
- ğŸ’¾ **Persistenza** delle conversazioni su file JSON
- ğŸ“¥ **Export** in Markdown, JSON, TXT, PDF + Batch ZIP
- ğŸ“š **Knowledge Base RAG** - Interroga documenti locali e wiki!
- ğŸŒ **Multi-Wiki** - MediaWiki + DokuWiki support
- ğŸ“ **File Upload in Chat** - Allega PDF, DOCX, TXT, immagini
- ğŸ” **Privacy-First Protection** - Sistema completo protezione dati sensibili
- ğŸ¨ **UI moderna** con temi chiaro/scuro
- â™»ï¸ **Architettura modulare** - Codice organizzato in packages

---

## ğŸ†• NovitÃ  v1.6.1 - Approccio Socratico ğŸ§ 

### La Filosofia
DeepAiUG evolve da semplice chat a **strumento socratico**. Ispirato al concetto di "capitale semantico" (Floridi/Quartarone):

> **L'AI produce significato plausibile, ma il SENSO lo costruisce l'umano.**

### ğŸ”„ Bottone "Genera alternative"
Sotto ogni risposta AI appare un nuovo bottone che genera **3 interpretazioni alternative** dello stesso problema.

**PerchÃ© Ã¨ utile?**
- Stimola il pensiero critico
- Mostra che ogni risposta ha assunzioni implicite
- Aiuta a costruire comprensione, non solo ottenere risposte

**Le 4 capacitÃ  che DeepAiUG vuole allenare:**
1. **Costruzione di senso** - collegare informazioni
2. **Valutazione semantica** - capire cosa conta
3. **Contestualizzazione** - collocare nel contesto giusto
4. **Resistenza alla plausibilitÃ ** - non fidarsi del "suona giusto"

### ğŸ”® Prossime Feature Socratiche
- **v1.7.0**: Bottoni "ğŸ¤” Assunzioni" + "âš ï¸ Limiti"
- **v1.8.0**: Toggle modalitÃ  (Veloce/Standard/Socratico)

---

## NovitÃ  v1.6.0

### ğŸŒŠ Streaming Responses
Le risposte dell'AI ora appaiono **token-by-token in tempo reale**, come in ChatGPT!

**Provider supportati:**
- âœ… **Ollama locale**: Streaming perfetto
- âœ… **Remote host**: Streaming perfetto
- âš ï¸ **Cloud (OpenAI, etc)**: In arrivo

**Footer aggiornato:** ğŸ¤– DeepAiUG by Gilles

---

## NovitÃ  v1.5.x

### ğŸ“ File Upload in Chat
Allega file direttamente nella chat, come in ChatGPT/Claude.ai!

| Tipo | Formati | Note |
|------|---------|------|
| ğŸ“„ **Documenti** | PDF, TXT, MD, DOCX | Testo estratto e aggiunto al contesto |
| ğŸ–¼ï¸ **Immagini** | PNG, JPG, GIF, WEBP | Richiede modello Vision (LLaVA, Granite3.2-Vision) |

### ğŸ” Privacy-First Protection
Sistema completo per proteggere i tuoi documenti sensibili:

| Protezione | Descrizione |
|------------|-------------|
| ğŸ”’ **Upload bloccato su Cloud** | I file possono essere caricati solo con Ollama locale o Remote host |
| âš ï¸ **Privacy Dialog** | Warning automatico quando passi da Localâ†’Cloud con documenti in memoria |
| ğŸ“¢ **Banner promemoria** | Ricorda che la sessione contiene dati estratti da documenti |

---

## ğŸ—ï¸ Architettura v1.6.1

```
datapizza-streamlit-interface/
â”œâ”€â”€ app.py                    # â­ Entry point principale
â”œâ”€â”€ wiki_sources.yaml         # Configurazione sorgenti wiki
â”‚
â”œâ”€â”€ config/                   # ğŸ“ Configurazione
â”‚   â”œâ”€â”€ constants.py          # Costanti, WIKI_TYPES, VISION_MODELS
â”‚   â””â”€â”€ settings.py           # Loader settings, API keys
â”‚
â”œâ”€â”€ core/                     # ğŸ“ Logica core
â”‚   â”œâ”€â”€ llm_client.py         # Factory client LLM
â”‚   â”œâ”€â”€ conversation.py       # Gestione messaggi
â”‚   â”œâ”€â”€ persistence.py        # Salvataggio/caricamento
â”‚   â””â”€â”€ file_processors.py    # Estrazione testo da file
â”‚
â”œâ”€â”€ rag/                      # ğŸ“ Sistema RAG
â”‚   â”œâ”€â”€ models.py             # Document, Chunk
â”‚   â”œâ”€â”€ chunker.py            # TextChunker intelligente
â”‚   â”œâ”€â”€ vector_store.py       # ChromaDB + fallback
â”‚   â”œâ”€â”€ manager.py            # KnowledgeBaseManager
â”‚   â””â”€â”€ adapters/             # Sorgenti dati
â”‚       â”œâ”€â”€ local_folder.py   # File locali
â”‚       â”œâ”€â”€ mediawiki.py      # API MediaWiki
â”‚       â””â”€â”€ dokuwiki.py       # DokuWiki
â”‚
â”œâ”€â”€ export/                   # ğŸ“ Sistema export
â”‚   â””â”€â”€ exporters.py          # MD, JSON, TXT, PDF, ZIP
â”‚
â””â”€â”€ ui/                       # ğŸ“ Interfaccia utente
    â”œâ”€â”€ styles.py             # CSS
    â”œâ”€â”€ chat.py               # Rendering chat
    â”œâ”€â”€ file_upload.py        # Widget upload file
    â”œâ”€â”€ privacy_warning.py    # Dialog privacy
    â”œâ”€â”€ socratic/             # ğŸ§  NEW - Modulo socratico
    â”‚   â”œâ”€â”€ prompts.py        # Template prompt
    â”‚   â””â”€â”€ buttons.py        # Bottoni UI
    â””â”€â”€ sidebar/              # Componenti sidebar
```

---

## ğŸš€ Quick Start

### Prerequisiti

```bash
# Python 3.9+
python --version

# Ollama (per modelli locali)
ollama --version
ollama list  # verifica modelli installati
```

---

## ğŸš€ Installazione

### Metodo 1: Script Automatico (Consigliato) â­

#### Linux/Mac
```bash
git clone https://github.com/EnzoGitHub27/datapizza-streamlit-interface.git
cd datapizza-streamlit-interface
chmod +x install.sh
./install.sh
```

#### Windows
```bash
git clone https://github.com/EnzoGitHub27/datapizza-streamlit-interface.git
cd datapizza-streamlit-interface
install.bat
```

---

### Metodo 2: Installazione Manuale Passo-Passo

#### 1. Clona il repository
```bash
git clone https://github.com/EnzoGitHub27/datapizza-streamlit-interface.git
cd datapizza-streamlit-interface
```

#### 2. Crea un ambiente virtuale
```bash
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# oppure
venv\Scripts\activate  # Windows
```

#### 3. Installa le dipendenze nell'ordine corretto

```bash
# 3.1 - Dipendenze base
pip install streamlit python-dotenv reportlab pyyaml

# 3.2 - Datapizza AI core (PRIMA dei client!)
pip install datapizza-ai

# 3.3 - Client provider (DOPO datapizza-ai)
pip install datapizza-ai-clients-openai-like  # Per Ollama
pip install datapizza-ai-clients-openai       # Per OpenAI
pip install datapizza-ai-clients-anthropic    # Per Anthropic
pip install datapizza-ai-clients-google       # Per Google
```

#### 4. Dipendenze aggiuntive
```bash
pip install chromadb beautifulsoup4 PyPDF2    # RAG
pip install mwclient dokuwiki                  # Wiki
pip install python-docx Pillow                 # File Upload
```

---

### Metodo 3: Poetry

```bash
poetry env use python3.12
poetry install
poetry shell
```

---

## â–¶ï¸ Avvio

```bash
streamlit run app.py
```

---

## ğŸ”§ Configurazione API Keys

### Opzione A: File .env
```env
OPENAI_API_KEY=sk-your-openai-key-here
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here
GOOGLE_API_KEY=your-google-gemini-key-here
```

### Opzione B: File secrets
```bash
mkdir -p secrets
echo "sk-your-key" > secrets/openai_key.txt
```

### Opzione C: Interfaccia Web
Puoi inserire le API keys direttamente dall'interfaccia Streamlit!

---

## ğŸ“š Knowledge Base RAG

### Sorgenti Supportate

| Tipo | Descrizione | Pacchetto |
|------|-------------|-----------|
| ğŸ“ **Cartella Locale** | File MD, TXT, HTML, PDF | - |
| ğŸŒ **MediaWiki** | Wikipedia-like wikis | `mwclient` |
| ğŸ“˜ **DokuWiki** | Wiki per documentazione | `dokuwiki` |

### Privacy Mode ğŸ”’

Quando la Knowledge Base Ã¨ attiva:
- â˜ï¸ **Cloud provider BLOCCATO** automaticamente
- ğŸ’» Solo **Ollama locale** o **Remote host** permessi
- ğŸ”’ I tuoi documenti **non escono mai** dal tuo computer

---

## ğŸ”§ Modelli Ollama Consigliati

```bash
# Modelli generali
ollama pull llama3.2
ollama pull mistral
ollama pull qwen2.5

# Modelli per coding
ollama pull qwen2.5-coder

# Modelli multimodali (per immagini)
ollama pull llava
ollama pull granite3.2-vision

# Modello per embeddings (RAG)
ollama pull nomic-embed-text
```

---

## ğŸ“‹ Dipendenze

```txt
# Core
streamlit>=1.28.0
datapizza-ai
datapizza-ai-clients-openai-like
python-dotenv>=1.0.0
pyyaml>=6.0

# RAG
chromadb>=0.4.0
beautifulsoup4>=4.12.0
PyPDF2>=3.0.0

# Wiki Adapters
mwclient>=0.10.0
dokuwiki>=0.1.0

# File Upload
python-docx>=0.8.0
Pillow>=10.0.0

# Export
reportlab>=4.0.0
```

---

## ğŸ—ºï¸ Roadmap

Vedi [ROADMAP.md](ROADMAP.md) per il piano completo.

| Versione | Feature | Stato |
|----------|---------|-------|
| v1.6.1 | ğŸ§  Bottoni Socratici | âœ… |
| v1.7.0 | ğŸ§  Assunzioni + Limiti | ğŸ“‹ |
| v1.8.0 | ğŸ§  Toggle modalitÃ  | ğŸ“‹ |
| v2.0.0 | Semantic Layer | ğŸ¯ |

---

## ğŸ¤ Contributing

Contribuzioni benvenute! Vedi [CONTRIBUTING.md](CONTRIBUTING.md).

1. Fork del repository
2. Crea un branch (`git checkout -b feature/nuova-feature`)
3. Commit (`git commit -m 'feat: aggiungi nuova feature'`)
4. Push (`git push origin feature/nuova-feature`)
5. Apri una Pull Request

---

## ğŸ“œ License

MIT License - vedi [LICENSE](LICENSE)

---

## ğŸ‘¥ Credits

- **DeepAiUG** - Community italiana AI
- **Datapizza** - Framework LLM
- **Streamlit** - UI Framework

---

## ğŸ“ Contatti

- ğŸŒ [DeepAiUG](https://deepaiug.it)
- ğŸ’¬ Issues su GitHub
- ğŸ“§ info@deepaiug.it

---

*Made with â¤ï¸ by DeepAiUG Community*
